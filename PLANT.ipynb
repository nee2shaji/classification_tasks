{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLANT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E5gFj11rOwE"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.environ['TRAIN_DATA_PATH'] = \"https://raw.githubusercontent.com/nee2shaji/IIITH_Sem3/master/plant_train.csv\"\n",
        "os.environ['TEST_DATA_PATH'] = \"https://raw.githubusercontent.com/nee2shaji/IIITH_Sem3/master/plant_test.csv\"\n",
        "pd.options.display.max_columns = None\n",
        "TRAIN_DATA_PATH = os.getenv(\"TRAIN_DATA_PATH\")\n",
        "TEST_DATA_PATH = os.getenv(\"TEST_DATA_PATH\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "T7tRLKVC46UL",
        "outputId": "a563cf8e-b5c9-4513-f96a-4cb8a659225f"
      },
      "source": [
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "train_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "      <th>V51</th>\n",
              "      <th>V52</th>\n",
              "      <th>V53</th>\n",
              "      <th>V54</th>\n",
              "      <th>V55</th>\n",
              "      <th>V56</th>\n",
              "      <th>V57</th>\n",
              "      <th>V58</th>\n",
              "      <th>V59</th>\n",
              "      <th>V60</th>\n",
              "      <th>V61</th>\n",
              "      <th>V62</th>\n",
              "      <th>V63</th>\n",
              "      <th>V64</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.112310</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.003906</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>0.075195</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.034180</td>\n",
              "      <td>0.003906</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.011719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008789</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.021484</td>\n",
              "      <td>0.017578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035156</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067383</td>\n",
              "      <td>0.021484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087891</td>\n",
              "      <td>0.026367</td>\n",
              "      <td>0.011719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030273</td>\n",
              "      <td>0.022461</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.11426</td>\n",
              "      <td>0.030273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009766</td>\n",
              "      <td>0.099609</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.009766</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003906</td>\n",
              "      <td>0.070312</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016602</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.069336</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009766</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>0.027344</td>\n",
              "      <td>0.071289</td>\n",
              "      <td>0.022461</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013672</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106450</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.038086</td>\n",
              "      <td>0.078125</td>\n",
              "      <td>0.027344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035156</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.008789</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040039</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013672</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>0.020508</td>\n",
              "      <td>0.011719</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008789</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.034180</td>\n",
              "      <td>0.020508</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.016602</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.074219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.028320</td>\n",
              "      <td>0.009766</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.040039</td>\n",
              "      <td>0.011719</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018555</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.019531</td>\n",
              "      <td>0.021484</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049805</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>0.035156</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.013672</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025391</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.020508</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.037109</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00293</td>\n",
              "      <td>0.017578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011719</td>\n",
              "      <td>0.045898</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.012695</td>\n",
              "      <td>0.034180</td>\n",
              "      <td>0.026367</td>\n",
              "      <td>0.003906</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.019531</td>\n",
              "      <td>0.030273</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.060547</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.008789</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.080078</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.239260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013672</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.019531</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.416020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.058594</td>\n",
              "      <td>0.003906</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049805</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003906</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159180</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.017578</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.003906</td>\n",
              "      <td>0.057617</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072266</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026367</td>\n",
              "      <td>0.027344</td>\n",
              "      <td>0.092773</td>\n",
              "      <td>0.034180</td>\n",
              "      <td>0.086914</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022461</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124020</td>\n",
              "      <td>0.024414</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0  0.112310  0.005859  0.007812  0.002930  0.003906  0.012695  0.075195   \n",
              "1  0.009766  0.002930  0.000000  0.079102  0.000000  0.000000  0.006836   \n",
              "2  0.004883  0.004883  0.002930  0.034180  0.020508  0.000977  0.005859   \n",
              "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.006836  0.000000   \n",
              "4  0.000000  0.000000  0.000000  0.049805  0.000000  0.001953  0.000000   \n",
              "\n",
              "         V8        V9       V10       V11  V12       V13       V14       V15  \\\n",
              "0  0.005859  0.034180  0.003906  0.000000  0.0  0.006836  0.011719  0.000000   \n",
              "1  0.000000  0.003906  0.070312  0.000977  0.0  0.000000  0.000000  0.002930   \n",
              "2  0.016602  0.004883  0.010742  0.074219  0.0  0.002930  0.028320  0.009766   \n",
              "3  0.000000  0.010742  0.000000  0.016602  0.0  0.000977  0.000977  0.080078   \n",
              "4  0.000000  0.003906  0.000000  0.159180  0.0  0.004883  0.017578  0.000000   \n",
              "\n",
              "        V16       V17       V18       V19       V20  V21       V22       V23  \\\n",
              "0  0.000000  0.008789  0.001953  0.021484  0.017578  0.0  0.000000  0.001953   \n",
              "1  0.000000  0.016602  0.000977  0.069336  0.007812  0.0  0.000000  0.009766   \n",
              "2  0.000000  0.001953  0.004883  0.040039  0.011719  0.0  0.018555  0.001953   \n",
              "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n",
              "4  0.000977  0.000977  0.000000  0.000000  0.000977  0.0  0.040039  0.000000   \n",
              "\n",
              "        V24       V25       V26       V27       V28       V29       V30  \\\n",
              "0  0.000000  0.012695  0.000000  0.035156  0.012695  0.004883  0.012695   \n",
              "1  0.046875  0.027344  0.071289  0.022461  0.000000  0.013672  0.000000   \n",
              "2  0.019531  0.021484  0.062500  0.005859  0.000000  0.049805  0.012695   \n",
              "3  0.002930  0.000000  0.024414  0.000000  0.000000  0.001953  0.000000   \n",
              "4  0.000977  0.000000  0.108400  0.000000  0.000000  0.006836  0.005859   \n",
              "\n",
              "        V31       V32       V33       V34       V35  V36       V37       V38  \\\n",
              "0  0.000977  0.000000  0.000000  0.067383  0.021484  0.0  0.000000  0.087891   \n",
              "1  0.015625  0.000000  0.106450  0.000977  0.000000  0.0  0.054688  0.001953   \n",
              "2  0.035156  0.004883  0.013672  0.006836  0.006836  0.0  0.025391  0.010742   \n",
              "3  0.001953  0.000000  0.054688  0.000000  0.000000  0.0  0.239260  0.000000   \n",
              "4  0.002930  0.003906  0.057617  0.000000  0.000977  0.0  0.072266  0.000000   \n",
              "\n",
              "        V39       V40       V41       V42       V43       V44       V45  \\\n",
              "0  0.026367  0.011719  0.000000  0.000000  0.030273  0.022461  0.010742   \n",
              "1  0.038086  0.078125  0.027344  0.000000  0.035156  0.001953  0.008789   \n",
              "2  0.020508  0.031250  0.001953  0.001953  0.037109  0.001953  0.000000   \n",
              "3  0.000000  0.000000  0.004883  0.000977  0.000000  0.000000  0.000000   \n",
              "4  0.000000  0.000000  0.000000  0.006836  0.000000  0.000000  0.000000   \n",
              "\n",
              "       V46       V47  V48       V49       V50       V51       V52       V53  \\\n",
              "0  0.11426  0.030273  0.0  0.005859  0.000977  0.000000  0.000000  0.000977   \n",
              "1  0.00000  0.010742  0.0  0.000977  0.006836  0.001953  0.000000  0.040039   \n",
              "2  0.00293  0.017578  0.0  0.011719  0.045898  0.039062  0.012695  0.034180   \n",
              "3  0.00000  0.000000  0.0  0.013672  0.006836  0.019531  0.000000  0.008789   \n",
              "4  0.00000  0.000977  0.0  0.026367  0.027344  0.092773  0.034180  0.086914   \n",
              "\n",
              "        V54       V55  V56       V57       V58       V59       V60  V61  \\\n",
              "0  0.010742  0.002930  0.0  0.027344  0.000000  0.004883  0.000000  0.0   \n",
              "1  0.015625  0.000000  0.0  0.013672  0.012695  0.020508  0.011719  0.0   \n",
              "2  0.026367  0.003906  0.0  0.006836  0.019531  0.030273  0.006836  0.0   \n",
              "3  0.000000  0.000000  0.0  0.000000  0.025391  0.000000  0.416020  0.0   \n",
              "4  0.002930  0.000000  0.0  0.000000  0.022461  0.007812  0.002930  0.0   \n",
              "\n",
              "        V62       V63       V64  class  \n",
              "0  0.000000  0.009766  0.099609     54  \n",
              "1  0.024414  0.000000  0.008789     95  \n",
              "2  0.060547  0.001953  0.008789      6  \n",
              "3  0.058594  0.003906  0.000000     12  \n",
              "4  0.124020  0.024414  0.000000     98  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYQZdlOgzHH"
      },
      "source": [
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "\n",
        "neg_data = train_data[train_data['class'] == 0]\n",
        "pos_data = train_data[train_data['class'] == 1]\n",
        "\n",
        "sns.pairplot(train_data, hue='class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJm98Zx75pBA"
      },
      "source": [
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "cor = train_data.corr()\n",
        "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzhJbLUlLNFH"
      },
      "source": [
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from sklearn import model_selection\n",
        "\n",
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "Target = ['class']\n",
        "data1_x_bin = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
        "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
        "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31',\n",
        "       'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41',\n",
        "       'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51',\n",
        "       'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61',\n",
        "       'V62', 'V63', 'V64']\n",
        "\n",
        "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
        "MLA = [\n",
        "    #Ensemble Methods\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    ensemble.BaggingClassifier(),\n",
        "    ensemble.ExtraTreesClassifier(),\n",
        "    ensemble.GradientBoostingClassifier(),\n",
        "    ensemble.RandomForestClassifier(),\n",
        "\n",
        "    #Gaussian Processes\n",
        "    gaussian_process.GaussianProcessClassifier(),\n",
        "    \n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "    linear_model.PassiveAggressiveClassifier(),\n",
        "    linear_model.RidgeClassifierCV(),\n",
        "    linear_model.SGDClassifier(),\n",
        "    linear_model.Perceptron(),\n",
        "    \n",
        "    #Navies Bayes\n",
        "    naive_bayes.BernoulliNB(),\n",
        "    naive_bayes.GaussianNB(),\n",
        "    \n",
        "    #Nearest Neighbor\n",
        "    neighbors.KNeighborsClassifier(),\n",
        "    \n",
        "    #SVM\n",
        "    svm.SVC(probability=True),\n",
        "    svm.NuSVC(probability=True),\n",
        "    svm.LinearSVC(),\n",
        "    \n",
        "    #Trees    \n",
        "    tree.DecisionTreeClassifier(),\n",
        "    tree.ExtraTreeClassifier(),\n",
        "    \n",
        "    #Discriminant Analysis\n",
        "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "  \n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "#note: this is an alternative to train_test_split\n",
        "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "\n",
        "#create table to compare MLA metrics\n",
        "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = train_data[Target]\n",
        "\n",
        "#index through MLA and save performance to table\n",
        "row_index = 0\n",
        "for alg in MLA:\n",
        "\n",
        "    #set name and parameters\n",
        "    MLA_name = alg.__class__.__name__\n",
        "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
        "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
        "    \n",
        "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
        "    cv_results = model_selection.cross_validate(alg, train_data[data1_x_bin], train_data[Target], cv  = cv_split, return_train_score=True)\n",
        "\n",
        "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
        "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
        "    \n",
        "\n",
        "    #save MLA predictions - see section 6 for usage\n",
        "    alg.fit(train_data[data1_x_bin], train_data[Target])\n",
        "    MLA_predict[MLA_name] = alg.predict(train_data[data1_x_bin])\n",
        "    \n",
        "    row_index+=1\n",
        "\n",
        "    \n",
        "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MFETy_ay7Bv"
      },
      "source": [
        "MLA_compare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1mV4o6OO66b"
      },
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "\n",
        "# Train and test data paths will be available as env variables during evaluation\n",
        "TRAIN_DATA_PATH = os.getenv(\"TRAIN_DATA_PATH\")\n",
        "TEST_DATA_PATH = os.getenv(\"TEST_DATA_PATH\")\n",
        "\n",
        "# Prepare the training data\n",
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "X_train, y_train = train_data.iloc[:,:-1], train_data.iloc[:,-1]\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train_scaled = sc.fit_transform(X_train)\n",
        "\n",
        "test_data = pd.read_csv(TEST_DATA_PATH)\n",
        "X_test_scaled = sc.transform(test_data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpxeXEf2yf_n"
      },
      "source": [
        "parameters = {\n",
        "    \"loss\":[\"deviance\"],\n",
        "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
        "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
        "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
        "    \"max_depth\":[3,5,8],\n",
        "    \"max_features\":[\"log2\",\"sqrt\"],\n",
        "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
        "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
        "    \"n_estimators\":[10]\n",
        "    }\n",
        "\n",
        "\n",
        "clf = GridSearchCV(GradientBoostingClassifier(), parameters, scoring=\"f1_micro\", n_jobs=-1)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf.score(X_train, y_train))\n",
        "print(clf.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RysIkcJfSuxV"
      },
      "source": [
        "param_grid = { \n",
        "    'n_estimators': [200, 500, 1000],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [4,5,6,7,8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "rfc=RandomForestClassifier(random_state=42)\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5, scoring='f1_micro')\n",
        "CV_rfc.fit(X_train_scaled, y_train)\n",
        "print(CV_rfc.best_params_, CV_rfc.score(X_train_scaled, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hSbCuYoTg-5"
      },
      "source": [
        "parameters = {'kernel':['linear'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
        "svc = SVC()\n",
        "clfsvc = GridSearchCV(estimator = svc, param_grid = parameters, scoring='f1_micro')\n",
        "clfsvc.fit(X_train_scaled, y_train)\n",
        "print(clfsvc.best_params_, clfsvc.score(X_train_scaled, y_train))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfmr0k_CyQFC"
      },
      "source": [
        "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
        "logreg=LogisticRegression()\n",
        "logreg_cv=GridSearchCV(estimator = logreg,param_grid = grid,cv=10, scoring='f1_micro')\n",
        "logreg_cv.fit(X_train_scaled,y_train)\n",
        "print(logreg_cv.best_params_, logreg_cv.score(X_train_scaled, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B6ND5pvUd5A"
      },
      "source": [
        "logreg=LogisticRegression(C=1.0, penalty='l2')\n",
        "svc = LinearSVC(C=0.1)\n",
        "rfc = RandomForestClassifier(criterion='entropy', max_depth=6, max_features='auto', n_estimators=500)\n",
        "gbc = GradientBoostingClassifier()\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "clf = VotingClassifier(estimators=[('rfc', rfc), ('lr', logreg),\n",
        "('svc', svc), ('lda',lda),('gbc',gbc)], voting='soft')\n",
        "\n",
        "clf = clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "clf.predict(X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22nF-jnAykrW"
      },
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['clf'] = clf.predict(X_test_scaled)\n",
        "\n",
        "# Export the prediction as submission.csv\n",
        "submission.to_csv('submission.csv', header=['class'], index=False) \n",
        "submission"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}